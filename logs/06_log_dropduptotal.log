==================================================== test session starts =====================================================
platform linux -- Python 3.10.8, pytest-7.2.0, pluggy-1.0.0
rootdir: /home/jovyan
plugins: anyio-3.6.2
collected 13 items

work/test_dropdup.py Directorio:  ['.profile', '.bash_logout', '.bashrc', '.cache', '.bash_history', '.astropy', '.jupyter', '.local', '.pytest_cache', '.ipython', '.conda', '.config', '.npm', '.wget-hsts', 'work']
.test_drop_duplicates_pandas_1M

RAM ocupada ANTES del test: 
19.2
%

RAM ocupada DESPUÉS del test: 
21.0
%

.test_drop_duplicates_pandas_5M

RAM ocupada ANTES del test: 
19.4
%

RAM ocupada DESPUÉS del test: 
26.7
%

.test_drop_duplicates_pandas_10M

RAM ocupada ANTES del test: 
20.3
%

RAM ocupada DESPUÉS del test: 
35.1
%

.test_drop_duplicates_pandas_25M

RAM ocupada ANTES del test: 
21.4
%

RAM ocupada DESPUÉS del test: 
48.5
%

.test_drop_duplicates_dask_1M

RAM ocupada ANTES del test: 
16.8
%

RAM ocupada DESPUÉS del test: 
16.8
%

.test_drop_duplicates_dask_5M

RAM ocupada ANTES del test: 
17.4
%

RAM ocupada DESPUÉS del test: 
17.4
%

.test_drop_duplicates_dask_10M

RAM ocupada ANTES del test: 
18.2
%

RAM ocupada DESPUÉS del test: 
18.2
%

.test_drop_duplicates_dask_25M

RAM ocupada ANTES del test: 
16.4
%

RAM ocupada DESPUÉS del test: 
16.4
%

.23/01/23 23:20:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
test_drop_duplicates_pyspark_1M

RAM ocupada ANTES del test: 
16.4
%

RAM ocupada DESPUÉS del test: 
21.3
%

.test_drop_duplicates_pyspark_5M

RAM ocupada ANTES del test: 
21.4
%

RAM ocupada DESPUÉS del test: 
21.7
%

.test_drop_duplicates_pyspark_10M

RAM ocupada ANTES del test: 
21.7
%

RAM ocupada DESPUÉS del test: 
21.7
%

.test_drop_duplicates_pyspark_25M

RAM ocupada ANTES del test: 
21.8
%

RAM ocupada DESPUÉS del test: 
22.0
%

.

====================================================== warnings summary ======================================================
work/test_dropdup.py::Test::test_drop_duplicates_pyspark_1M
work/test_dropdup.py::Test::test_drop_duplicates_pyspark_5M
work/test_dropdup.py::Test::test_drop_duplicates_pyspark_10M
work/test_dropdup.py::Test::test_drop_duplicates_pyspark_25M
  /usr/local/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
===================================================== slowest durations ======================================================
139.27s call     work/test_dropdup.py::Test::test_drop_duplicates_pandas_25M
37.10s call     work/test_dropdup.py::Test::test_drop_duplicates_pandas_10M
16.93s call     work/test_dropdup.py::Test::test_drop_duplicates_pandas_5M
9.03s call     work/test_dropdup.py::Test::test_drop_duplicates_pyspark_1M
3.00s call     work/test_dropdup.py::Test::test_drop_duplicates_dask_1M
2.62s call     work/test_dropdup.py::Test::test_drop_duplicates_pandas_1M
0.47s call     work/test_dropdup.py::Test::test_drop_duplicates_pyspark_5M
0.43s call     work/test_dropdup.py::Test::test_drop_duplicates_pyspark_25M
0.41s call     work/test_dropdup.py::Test::test_drop_duplicates_pyspark_10M
0.13s call     work/test_dropdup.py::Test::test_drop_duplicates_dask_10M
0.10s call     work/test_dropdup.py::Test::test_drop_duplicates_dask_5M
0.10s call     work/test_dropdup.py::Test::test_drop_duplicates_dask_25M
0.02s teardown work/test_dropdup.py::Test::test_drop_duplicates_pandas_25M
0.01s setup    work/test_dropdup.py::Test::test_drop_duplicates_dask_1M

(25 durations < 0.005s hidden.  Use -vv to show these durations.)
========================================= 13 passed, 4 warnings in 212.19s (0:03:32) =========================================
